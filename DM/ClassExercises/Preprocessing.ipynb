{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Imputer:\n",
    "    \"\"\"缺失值处理方法\"\"\"\n",
    "\n",
    "    def __init__(self, missing_value=\"NaN\", ):\n",
    "        \"\"\"\n",
    "        :param missing_value: 缺失值符合\n",
    "        \"\"\"\n",
    "        self.missing_value = missing_value\n",
    "\n",
    "    def fit(self, colValue, valueType=\"numeric\", strategy=\"mean\"):\n",
    "        if valueType == \"numeric\":  # 处理数值型数据\n",
    "            missing_value_index = []  # 缺失值索引\n",
    "            if strategy == \"mean\":\n",
    "                no_missing_sum = 0\n",
    "                for idx, value in enumerate(colValue):\n",
    "                    if value == self.missing_value:\n",
    "                        missing_value_index.append(idx)  # 将缺失值得索引存储到列表，加快后期填补速率\n",
    "                        continue\n",
    "                    no_missing_sum += float(value)  # 对未缺失的值求和\n",
    "                mu = no_missing_sum / (len(colValue) - len(missing_value_index))  # 求均值，未缺失的个数为总个数减缺失的数量\n",
    "                for index in missing_value_index:  # 填补缺失值\n",
    "                    colValue[index] = mu\n",
    "        elif valueType == \"category\":  # 处理离散型数据\n",
    "            if strategy == \"mode\":\n",
    "                value_count = {}\n",
    "                missing_value_index = []  # 缺失值索引\n",
    "                for idx, value in enumerate(colValue):\n",
    "                    if value[0] == \"-\":\n",
    "                        missing_value_index.append(idx)  # 将缺失值得索引存储到列表，加快后期填补速率\n",
    "                        continue\n",
    "                    value_count.setdefault(value, 0)\n",
    "                    value_count[value] += 1\n",
    "\n",
    "                max_key, max_value = max(value_count.items(), key=lambda x: x[1])  # 使用max函数查找字典最大值那个\n",
    "                for index in missing_value_index:  # 填补缺失值\n",
    "                    colValue[index] = max_key\n",
    "        else:\n",
    "            raise TypeError(\"给定值类型错误\")\n",
    "        return colValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_train_data(path):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError()\n",
    "    else:\n",
    "        train_data = [line.strip().split(',') for line in open(path)]\n",
    "    return train_data[1:], train_data[0]\n",
    "\n",
    "\n",
    "def merge(train_x, train_y):\n",
    "    for idx, value in enumerate(train_x):\n",
    "        if value[0] == train_y[idx][0]:\n",
    "            train_x[idx].append(train_y[idx][1])\n",
    "        else:\n",
    "            for train_row in train_y:\n",
    "                if value[0] == train_row[0]:\n",
    "                    train_x[idx].append(train_row[1])\n",
    "    return train_x\n",
    "\n",
    "\n",
    "def preprocessing(train_x, header_x, features_type):\n",
    "    len_row = len(train_x)  # 多少行\n",
    "    len_col = len(train_x[0][1:])  # 多少列\n",
    "    imputer = Imputer(\"-1\")\n",
    "    result_data = train_x\n",
    "    for col in range(1, len_col):\n",
    "        col_arr = []\n",
    "        for row in range(len_row):\n",
    "            col_arr.append(train_x[row][col])\n",
    "        if features_type[col][0] == header_x[col]:\n",
    "            col_value = imputer.fit(colValue=col_arr, valueType=features_type[col][1], strategy=features_type[col][1])\n",
    "            for row in range(len_row):\n",
    "                result_data[row][col] = col_value[row]\n",
    "    return result_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    train_x, header_x = load_train_data(\"../DataSet/character/train_x.csv\")\n",
    "    train_y, header_y = load_train_data(\"../DataSet/character/train_y.csv\")\n",
    "    features_type, header_type = load_train_data(\"../DataSet/character/features_type.csv\")\n",
    "    clean_data_un_label = preprocessing(train_x=train_x, header_x=header_x[1:], features_type=features_type)\n",
    "\n",
    "    clean_data_has_label = merge(clean_data_un_label, train_y)\n",
    "    header_x.append(\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1138"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x[0][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(clean_data_has_label,columns=header_x).to_csv(\"../DataSet/character/clean_data_has_label.csv\",index =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

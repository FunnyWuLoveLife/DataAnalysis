{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    def __init__(self, dataFormat):\n",
    "        \"\"\"\n",
    "        :param training_data_path: 训练数据路径\n",
    "        :param dataFormat: 数据的格式，形如：attr attr attr attr class\n",
    "        \"\"\"\n",
    "\n",
    "        # 获取数据行的格式\n",
    "        self.format = dataFormat.strip().split(\"\\t\")\n",
    "        # 先验概率\n",
    "        self.prior = {}\n",
    "        # 条件概率\n",
    "        self.conditional = {}\n",
    "        # 开始训练\n",
    "\n",
    "    def train(self, training_data_path):\n",
    "        \"\"\"\n",
    "        训练分类器，训练方法\n",
    "        :param training_data_path: 训练数据路径\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # 记录总共有多少条数据\n",
    "        total = 0\n",
    "        # 记录每个模型出现的次数\n",
    "        classes = {}\n",
    "        # 记录条件概率的次数\n",
    "        counts = {}\n",
    "\n",
    "        # 训练数据文件名\n",
    "        f = open(training_data_path, encoding='UTF-8')\n",
    "        lines = f.readlines()\n",
    "        f.close()\n",
    "        for line in lines:\n",
    "            # 分割一条记录\n",
    "            fields = line.strip().split(',')\n",
    "            # 忽略的字段\n",
    "            ignore = []\n",
    "            # 特征向量\n",
    "            vector = []\n",
    "            # 分类\n",
    "            category = \"\"\n",
    "            # 根据给定的数据格式(这里已经转换为format列表)，查找给定数据的属性，并添加到特征向量中\n",
    "            for i in range(len(fields)):\n",
    "                if self.format[i] == 'num':\n",
    "                    vector.append(float(fields[i]))\n",
    "                elif self.format[i] == 'attr':\n",
    "                    vector.append(fields[i])\n",
    "                elif self.format[i] == 'class':\n",
    "                    category = fields[i]\n",
    "                    \n",
    "            # 总的记录数增加一条\n",
    "            total += 1\n",
    "            # 为classes，counts设置该分类的一个默认值\n",
    "            classes.setdefault(category, 0)\n",
    "            counts.setdefault(category, {})\n",
    "            # 分类数量加1\n",
    "            classes[category] += 1\n",
    "            # 处理各个特征，这些特征存储在特征向量vector中\n",
    "            col = 0\n",
    "            for columnValue in vector:\n",
    "                col += 1\n",
    "                counts[category].setdefault(col, {})\n",
    "                counts[category][col].setdefault(columnValue, 0)\n",
    "                counts[category][col][columnValue] += 1\n",
    "\n",
    "        # 计数结束，开始计算概率\n",
    "        # 计算先验概率P(h)\n",
    "        for (category, count) in classes.items():\n",
    "            self.prior[category] = count / total\n",
    "        # 计算条件概率P(h|D)\n",
    "        for (category, columns) in counts.items():\n",
    "            self.conditional.setdefault(category, {})\n",
    "            for (col, valueCounts) in columns.items():\n",
    "                self.conditional[category].setdefault(col, {})\n",
    "                for (attrValue, count) in valueCounts.items():\n",
    "                    self.conditional[category][col][attrValue] = (count / classes[category])\n",
    "\n",
    "    def classify(self, itemVector):\n",
    "        \"\"\"返回itemVector所属类别\"\"\"\n",
    "        results = []\n",
    "        for (category, prior) in self.prior.items():\n",
    "            prob = prior\n",
    "            col = 1\n",
    "            for attrValue in itemVector:\n",
    "                if attrValue not in self.conditional[category][col]:\n",
    "                    # 属性不存在，返回0概率\n",
    "                    prob = 0\n",
    "                else:\n",
    "                    prob = prob * self.conditional[category][col][attrValue]\n",
    "                col += 1\n",
    "            results.append((prob, category))\n",
    "        # 返回概率最高的结果\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.024691358024691357, 'i100'), (0.006584362139917694, 'i500')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Classifier(\"attr\\tattr\\tattr\\tattr\\tclass\")   \n",
    "c.train(\"../DataSet/NaiveBayesTestData\")\n",
    "c.classify(['appearance','active', 'moderate', 'no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataFormat = open(\"../DataSet/character/dataFormat\").readline()\n",
    "c = Classifier(dataFormat)\n",
    "\n",
    "c.train(\"../DataSet/character/train_data\")\n",
    "\n",
    "train_x_pd = pd.read_csv(\"../DataSet/character/train_x.csv\")\n",
    "label = pd.read_csv(\"../DataSet/character/train_y.csv\")\n",
    "label.columns = [\"ruid\", \"label\"]\n",
    "train_x_pd_hasLabel = train_x_pd.merge(label, left_on=\"uid\", right_on=\"ruid\")\n",
    "del train_x_pd_hasLabel[\"ruid\"]\n",
    "del train_x_pd_hasLabel[\"uid\"]\n",
    "test_data_str = []\n",
    "for idx, row in train_x_pd_hasLabel[14972:14973].iterrows():\n",
    "    oneData = []\n",
    "    for key in train_x_pd_hasLabel.keys():\n",
    "        oneData.append(row[key])\n",
    "    test_data_str.append(\"\\t\".join(map(str, oneData)))\n",
    "    \n",
    "print(c.classify(test_data_str[0].split(\"\\t\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

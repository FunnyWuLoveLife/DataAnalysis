{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x_file  = open(\"../DataSet/character/train_x.csv\")\n",
    "features_type_file = open(\"../DataSet/character/features_type.csv\")\n",
    "\n",
    "train_x = [row.replace('\"',\"\").replace('\\n',\"\").split(\",\") for row in train_x_file]\n",
    "\n",
    "features_type ={}\n",
    "for line in features_type_file:\n",
    "    line = line.replace('\"',\"\").replace('\\n',\"\").split(\",\")\n",
    "    features_type[line[0]] = line[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化字段除去重字典\n",
    "train_x_dict = { one:set() for one in train_x[0] }\n",
    "# 定义相应的字段的行下标\n",
    "train_x_header = { one:train_x[0].index(one) for one in train_x[0] }\n",
    "del train_x_dict[\"uid\"]\n",
    "# 去重\n",
    "for one in train_x[1:]:\n",
    "    for key in train_x_dict.keys():\n",
    "        if features_type[key] == \"category\":\n",
    "            value = one[train_x_index[key]]\n",
    "            if int(value) < 0 :\n",
    "                train_x_dict[key].add(\"NaN\")\n",
    "            else:\n",
    "                train_x_dict[key].add(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x_dict_temp={}\n",
    "for key in train_x_dict.keys():\n",
    "        if len(train_x_dict[key]):\n",
    "            train_x_dict_temp.setdefault(key,list(train_x_dict[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix ={}\n",
    "for row in train_x[1:]:\n",
    "    for key in train_x_dict_temp.keys():\n",
    "        feature_vector = [0 for i in range(len(train_x_dict_temp[key]))]\n",
    "        feature_matrix.setdefault(key,[])        \n",
    "        row_index = train_x_header[key]\n",
    "        row_key = row[row_index]\n",
    "        if int(row_key) < 0:\n",
    "            row_key = \"NaN\"\n",
    "        matrix_index = train_x_dict_temp[key].index(row_key)\n",
    "        feature_vector[matrix_index] = 1\n",
    "        feature_matrix[key].append(feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_x_pd = pd.read_csv(\"../DataSet/character/train_x.csv\")\n",
    "for key in feature_matrix.keys():\n",
    "    temp = pd.DataFrame(feature_matrix[key])\n",
    "    for idx,col in temp.items():\n",
    "        col_name = key+\"_\"+ str(idx)\n",
    "        train_x_pd.insert(1,col_name,col)\n",
    "    del train_x_pd[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出为文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x_pd.to_csv(\"../DataSet/character/train_x_OneHotEncoder.csv\",index =False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
